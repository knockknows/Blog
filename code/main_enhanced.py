from fastapi import FastAPI, HTTPException, status, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, HttpUrl, Field
from playwright.async_api import async_playwright, Browser, TimeoutError as PlaywrightTimeout
from typing import Literal, Optional, List
from contextlib import asynccontextmanager
from jose import JWTError, jwt
from passlib.context import CryptContext
from datetime import datetime, timedelta
import asyncio
import os
import logging

# ==========================================
# ë¡œê¹… ì„¤ì •
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==========================================
# JWT ì„¤ì •
# ==========================================
SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key-change-this-in-production-2024")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", "30"))

# ë¹„ë°€ë²ˆí˜¸ í•´ì‹± ì„¤ì •
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# HTTPBearer ìŠ¤í‚´ (JWT í† í° ê²€ì¦ìš©)
security = HTTPBearer()

# ==========================================
# ì „ì—­ ë³€ìˆ˜
# ==========================================
browser: Optional[Browser] = None

# ê°„ë‹¨í•œ ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” DB ì‚¬ìš©)
# ë¹„ë°€ë²ˆí˜¸: "secure_password_123"ì˜ bcrypt í•´ì‹œ
FAKE_USERS_DB = {
    "n8n_user": {
        "username": "n8n_user",
        "hashed_password": "$2b$12$5SxX04kP/aoQVwdrBW0eZeQGSeaOU2VUtUDFHZWPZ1D7N11ERRS8S"  # secure_password_123
    }
}

# ==========================================
# Lifespan Context Manager
# ==========================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ì²´ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•´ìš”."""
    global browser
    playwright_url = os.getenv("PLAYWRIGHT_SERVER_URL", "ws://playwright:3000")
    playwright_instance = None

    logger.info("ğŸš€ FastAPI ì„œë²„ ì‹œì‘ ì¤‘...")

    try:
        # Playwright ë¸Œë¼ìš°ì € ì—°ê²°
        logger.info(f"ğŸ“¡ Playwright Serverì— ì—°ê²° ì‹œë„: {playwright_url}")
        playwright_instance = await async_playwright().start()
        browser = await playwright_instance.chromium.connect(
            playwright_url,
            timeout=10000
        )
        logger.info("âœ… Playwright ë¸Œë¼ìš°ì € ì—°ê²° ì™„ë£Œ!")

        yield  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        if browser:
            await browser.close()
            logger.info("âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
        if playwright_instance:
            await playwright_instance.stop()
            logger.info("âœ… Playwright ì¢…ë£Œ ì™„ë£Œ")

# ==========================================
# FastAPI ì•± ìƒì„±
# ==========================================
app = FastAPI(
    title="N8N Playwright Scraper API",
    description="ìˆœìˆ˜ ìŠ¤í¬ë˜í•‘ ì „ë¬¸ API (ë°ì´í„° ê´€ë¦¬ëŠ” N8Nì´ ë‹´ë‹¹)",
    version="2.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# Pydantic ëª¨ë¸
# ==========================================
class LoginRequest(BaseModel):
    username: str
    password: str

class Token(BaseModel):
    access_token: str
    token_type: str
    expires_in: int

class ScrapeRequest(BaseModel):
    url: HttpUrl
    wait_for: Literal["load", "domcontentloaded", "networkidle"] = "networkidle"
    timeout: int = Field(default=30000, ge=5000, le=60000)

class BatchScrapeRequest(BaseModel):
    urls: List[HttpUrl]
    wait_for: Literal["load", "domcontentloaded", "networkidle"] = "networkidle"
    timeout: int = Field(default=30000, ge=5000, le=60000)
    max_concurrent: int = Field(default=5, ge=1, le=10)

class ScrapeResponse(BaseModel):
    url: str
    title: str
    content: str
    success: bool
    error: Optional[str] = None

# ==========================================
# JWT ê´€ë ¨ í•¨ìˆ˜
# ==========================================
def verify_password(plain_password: str, hashed_password: str) -> bool:
    """ë¹„ë°€ë²ˆí˜¸ ê²€ì¦"""
    return pwd_context.verify(plain_password, hashed_password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """JWT ì•¡ì„¸ìŠ¤ í† í° ìƒì„±"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)) -> str:
    """JWT í† í° ê²€ì¦ ë° ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="í† í° ê²€ì¦ ì‹¤íŒ¨",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        token = credentials.credentials
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
        return username
    except JWTError:
        raise credentials_exception

# ==========================================
# ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
# ==========================================
async def scrape_single_url(
    url: str,
    wait_for: str,
    timeout: int
) -> ScrapeResponse:
    """ë‹¨ì¼ URL ìŠ¤í¬ë˜í•‘"""
    if not browser:
        return ScrapeResponse(
            url=url,
            title="",
            content="",
            success=False,
            error="ë¸Œë¼ìš°ì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )

    context = None
    page = None

    try:
        # ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        )
        page = await context.new_page()

        # í˜ì´ì§€ ì´ë™
        logger.info(f"ğŸŒ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {url}")
        await page.goto(str(url), wait_until=wait_for, timeout=timeout)

        # ë°ì´í„° ì¶”ì¶œ
        title = await page.title()
        content = await page.content()

        logger.info(f"âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ: {url}")
        return ScrapeResponse(
            url=str(url),
            title=title,
            content=content,
            success=True
        )

    except PlaywrightTimeout:
        logger.error(f"â° íƒ€ì„ì•„ì›ƒ: {url}")
        return ScrapeResponse(
            url=str(url),
            title="",
            content="",
            success=False,
            error=f"íƒ€ì„ì•„ì›ƒ ({timeout}ms ì´ˆê³¼)"
        )
    except Exception as e:
        logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {url} - {str(e)}")
        return ScrapeResponse(
            url=str(url),
            title="",
            content="",
            success=False,
            error=str(e)
        )
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if page:
            await page.close()
        if context:
            await context.close()

# ==========================================
# API ì—”ë“œí¬ì¸íŠ¸
# ==========================================
@app.get("/", tags=["ê¸°ë³¸"])
async def root():
    """API ì •ë³´"""
    return {
        "name": "N8N Playwright Scraper API",
        "version": "2.0.0",
        "description": "ìˆœìˆ˜ ìŠ¤í¬ë˜í•‘ ì „ë¬¸ API (ë°ì´í„° ê´€ë¦¬ëŠ” N8Nì´ ë‹´ë‹¹)",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health", tags=["ê¸°ë³¸"])
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    browser_status = "connected" if browser else "disconnected"
    is_healthy = browser is not None

    return {
        "status": "healthy" if is_healthy else "unhealthy",
        "browser": browser_status,
        "note": "ë°ì´í„° ê´€ë¦¬ëŠ” N8N PostgreSQLì—ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤."
    }

@app.post("/login", response_model=Token, tags=["ì¸ì¦"])
async def login(request: LoginRequest):
    """
    JWT í† í° ë°œê¸‰

    - **username**: n8n_user
    - **password**: secure_password_123
    """
    user = FAKE_USERS_DB.get(request.username)

    if not user or not verify_password(request.password, user["hashed_password"]):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.",
            headers={"WWW-Authenticate": "Bearer"},
        )

    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user["username"]},
        expires_delta=access_token_expires
    )

    logger.info(f"âœ… JWT í† í° ë°œê¸‰: {user['username']}")

    return Token(
        access_token=access_token,
        token_type="bearer",
        expires_in=ACCESS_TOKEN_EXPIRE_MINUTES * 60
    )

@app.post("/scrape", response_model=ScrapeResponse, tags=["ìŠ¤í¬ë˜í•‘"])
async def scrape(
    request: ScrapeRequest,
    current_user: str = Depends(get_current_user)
):
    """
    ë‹¨ì¼ URL ìŠ¤í¬ë˜í•‘

    - **url**: ìŠ¤í¬ë˜í•‘í•  URL
    - **wait_for**: í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° ì¡°ê±´ (load, domcontentloaded, networkidle)
    - **timeout**: íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ, 5000~60000)
    """
    logger.info(f"ğŸ“¥ ìŠ¤í¬ë˜í•‘ ìš”ì²­: {request.url} (ì‚¬ìš©ì: {current_user})")

    result = await scrape_single_url(
        url=str(request.url),
        wait_for=request.wait_for,
        timeout=request.timeout
    )

    return result

@app.post("/scrape/batch", response_model=List[ScrapeResponse], tags=["ìŠ¤í¬ë˜í•‘"])
async def batch_scrape(
    request: BatchScrapeRequest,
    current_user: str = Depends(get_current_user)
):
    """
    ë³‘ë ¬ ìŠ¤í¬ë˜í•‘ (ì—¬ëŸ¬ URL ë™ì‹œ ì²˜ë¦¬)

    - **urls**: ìŠ¤í¬ë˜í•‘í•  URL ë¦¬ìŠ¤íŠ¸
    - **wait_for**: í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸° ì¡°ê±´
    - **timeout**: íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ)
    - **max_concurrent**: ë™ì‹œ ì‹¤í–‰ ê°œìˆ˜ (1~10)
    """
    logger.info(f"ğŸ“¥ ë³‘ë ¬ ìŠ¤í¬ë˜í•‘ ìš”ì²­: {len(request.urls)}ê°œ URL (ì‚¬ìš©ì: {current_user})")

    # Semaphoreë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ
    semaphore = asyncio.Semaphore(request.max_concurrent)

    async def scrape_with_semaphore(url: HttpUrl):
        async with semaphore:
            return await scrape_single_url(
                url=str(url),
                wait_for=request.wait_for,
                timeout=request.timeout
            )

    # ë³‘ë ¬ ì‹¤í–‰
    tasks = [scrape_with_semaphore(url) for url in request.urls]
    results = await asyncio.gather(*tasks)

    success_count = sum(1 for r in results if r.success)
    logger.info(f"âœ… ë³‘ë ¬ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {success_count}/{len(results)} ì„±ê³µ")

    return results

# ==========================================
# ì—ëŸ¬ í•¸ë“¤ëŸ¬
# ==========================================
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    logger.error(f"HTTP ì˜ˆì™¸: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"ì¼ë°˜ ì˜ˆì™¸: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "detail": str(exc)
        }
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
